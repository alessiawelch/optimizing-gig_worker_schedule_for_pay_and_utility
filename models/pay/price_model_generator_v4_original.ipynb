{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4ad0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline      import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model  import LinearRegression, ElasticNetCV\n",
    "from sklearn.neighbors     import KNeighborsRegressor\n",
    "from sklearn.tree          import DecisionTreeRegressor\n",
    "from sklearn.ensemble      import (\n",
    "    GradientBoostingRegressor, AdaBoostRegressor,\n",
    "    RandomForestRegressor, ExtraTreesRegressor\n",
    ")\n",
    "from xgboost               import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics       import mean_absolute_error, root_mean_squared_error\n",
    "import pandas as pd, numpy as np\n",
    "import json, joblib\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d137d8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading  : C:\\Users\\aless\\OneDrive - Nexus365\\Thesis\\driver_data\\combined_path\\new_test\\original\\trips_original_0075_v2_with_predicted_distance_time.parquet\n",
      "Saving to : C:\\Users\\aless\\OneDrive - Nexus365\\Thesis\\driver_data\\models\\price\\model_artifacts\\price_v4_original\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path.cwd().resolve().parents[1]     \n",
    "COMBINED_DIR   = PROJECT_ROOT / \"combined_path\"\n",
    "OG_DIR = COMBINED_DIR / \"new_test\" / \"original\"\n",
    "CELL_FILE_ADDITION = \"original_0075_v2\"\n",
    "\n",
    "PARQUET_PATH    = OG_DIR / f\"trips_{CELL_FILE_ADDITION}_with_predicted_distance_time.parquet\"\n",
    "PARQUET_OUT    = OG_DIR / f\"trips_{CELL_FILE_ADDITION}_with_predicted_information.parquet\"\n",
    "\n",
    "PRICE_MODEL_DIR = PROJECT_ROOT / \"models\" / \"price\" / \"model_artifacts\" / \"price_v4_original\"\n",
    "PRICE_MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Reading  :\", PARQUET_PATH)\n",
    "print(\"Saving to :\", PRICE_MODEL_DIR)\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "df = pd.read_parquet(PARQUET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c6b639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PARQUET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f61236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 147,498 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_row</th>\n",
       "      <th>origin_col</th>\n",
       "      <th>dest_row</th>\n",
       "      <th>dest_col</th>\n",
       "      <th>begin_lat</th>\n",
       "      <th>begin_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>haversine_km</th>\n",
       "      <th>begintrip_timestamp_london</th>\n",
       "      <th>...</th>\n",
       "      <th>driver_id_offline_online</th>\n",
       "      <th>trip_distance_miles</th>\n",
       "      <th>trip_distance_km</th>\n",
       "      <th>osrm_sec</th>\n",
       "      <th>osrm_km</th>\n",
       "      <th>dow</th>\n",
       "      <th>month_idx</th>\n",
       "      <th>doy</th>\n",
       "      <th>km_pred</th>\n",
       "      <th>sec_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>51.440338</td>\n",
       "      <td>-0.159358</td>\n",
       "      <td>51.456711</td>\n",
       "      <td>-0.191571</td>\n",
       "      <td>2.880576</td>\n",
       "      <td>2016-04-28 17:23:20+01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>03d0deda558765c2fbf485c57117bf2a3537611151fb49...</td>\n",
       "      <td>2.789894</td>\n",
       "      <td>4.489888</td>\n",
       "      <td>398.700012</td>\n",
       "      <td>3.4857</td>\n",
       "      <td>3</td>\n",
       "      <td>24196</td>\n",
       "      <td>119</td>\n",
       "      <td>3.625828</td>\n",
       "      <td>664.820351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>51.445763</td>\n",
       "      <td>-0.191400</td>\n",
       "      <td>51.474430</td>\n",
       "      <td>-0.167369</td>\n",
       "      <td>3.596283</td>\n",
       "      <td>2016-04-28 17:50:48+01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>03d0deda558765c2fbf485c57117bf2a3537611151fb49...</td>\n",
       "      <td>3.236049</td>\n",
       "      <td>5.207903</td>\n",
       "      <td>626.099976</td>\n",
       "      <td>5.0948</td>\n",
       "      <td>3</td>\n",
       "      <td>24196</td>\n",
       "      <td>119</td>\n",
       "      <td>5.318336</td>\n",
       "      <td>955.559975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>51.479115</td>\n",
       "      <td>-0.166910</td>\n",
       "      <td>51.490761</td>\n",
       "      <td>-0.183790</td>\n",
       "      <td>1.744453</td>\n",
       "      <td>2016-04-28 18:10:50+01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>03d0deda558765c2fbf485c57117bf2a3537611151fb49...</td>\n",
       "      <td>1.491487</td>\n",
       "      <td>2.400309</td>\n",
       "      <td>302.100006</td>\n",
       "      <td>1.9474</td>\n",
       "      <td>3</td>\n",
       "      <td>24196</td>\n",
       "      <td>119</td>\n",
       "      <td>2.202951</td>\n",
       "      <td>542.938647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>51.487488</td>\n",
       "      <td>-0.191229</td>\n",
       "      <td>51.502617</td>\n",
       "      <td>-0.199705</td>\n",
       "      <td>1.781674</td>\n",
       "      <td>2016-04-28 18:24:59+01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>03d0deda558765c2fbf485c57117bf2a3537611151fb49...</td>\n",
       "      <td>1.642280</td>\n",
       "      <td>2.642988</td>\n",
       "      <td>389.100006</td>\n",
       "      <td>2.6575</td>\n",
       "      <td>3</td>\n",
       "      <td>24196</td>\n",
       "      <td>119</td>\n",
       "      <td>2.887826</td>\n",
       "      <td>690.397036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>51.444721</td>\n",
       "      <td>-0.148535</td>\n",
       "      <td>51.502235</td>\n",
       "      <td>-0.186893</td>\n",
       "      <td>6.925133</td>\n",
       "      <td>2016-04-28 21:06:02+01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>03d0deda558765c2fbf485c57117bf2a3537611151fb49...</td>\n",
       "      <td>8.204270</td>\n",
       "      <td>13.203459</td>\n",
       "      <td>1175.900024</td>\n",
       "      <td>7.8614</td>\n",
       "      <td>3</td>\n",
       "      <td>24196</td>\n",
       "      <td>119</td>\n",
       "      <td>8.588139</td>\n",
       "      <td>1328.159043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin_row  origin_col  dest_row  dest_col  begin_lat  begin_lng  \\\n",
       "0           5          12         7         7  51.440338  -0.159358   \n",
       "1           6           7         9        11  51.445763  -0.191400   \n",
       "2          10          11        12         8  51.479115  -0.166910   \n",
       "3          11           7        13         6  51.487488  -0.191229   \n",
       "4           5          13        13         8  51.444721  -0.148535   \n",
       "\n",
       "     end_lat   end_lng  haversine_km begintrip_timestamp_london  ...  \\\n",
       "0  51.456711 -0.191571      2.880576  2016-04-28 17:23:20+01:00  ...   \n",
       "1  51.474430 -0.167369      3.596283  2016-04-28 17:50:48+01:00  ...   \n",
       "2  51.490761 -0.183790      1.744453  2016-04-28 18:10:50+01:00  ...   \n",
       "3  51.502617 -0.199705      1.781674  2016-04-28 18:24:59+01:00  ...   \n",
       "4  51.502235 -0.186893      6.925133  2016-04-28 21:06:02+01:00  ...   \n",
       "\n",
       "                            driver_id_offline_online  trip_distance_miles  \\\n",
       "0  03d0deda558765c2fbf485c57117bf2a3537611151fb49...             2.789894   \n",
       "1  03d0deda558765c2fbf485c57117bf2a3537611151fb49...             3.236049   \n",
       "2  03d0deda558765c2fbf485c57117bf2a3537611151fb49...             1.491487   \n",
       "3  03d0deda558765c2fbf485c57117bf2a3537611151fb49...             1.642280   \n",
       "4  03d0deda558765c2fbf485c57117bf2a3537611151fb49...             8.204270   \n",
       "\n",
       "   trip_distance_km     osrm_sec osrm_km  dow  month_idx  doy   km_pred  \\\n",
       "0          4.489888   398.700012  3.4857    3      24196  119  3.625828   \n",
       "1          5.207903   626.099976  5.0948    3      24196  119  5.318336   \n",
       "2          2.400309   302.100006  1.9474    3      24196  119  2.202951   \n",
       "3          2.642988   389.100006  2.6575    3      24196  119  2.887826   \n",
       "4         13.203459  1175.900024  7.8614    3      24196  119  8.588139   \n",
       "\n",
       "      sec_pred  \n",
       "0   664.820351  \n",
       "1   955.559975  \n",
       "2   542.938647  \n",
       "3   690.397036  \n",
       "4  1328.159043  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Loaded {len(df):,} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa48376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price_blended(models, df_new) -> np.ndarray:\n",
    "    FEATURES = models[\"features\"]\n",
    "    assert all(c in df_new.columns for c in FEATURES), \"Missing features for inference\"\n",
    "    X = df_new[FEATURES]\n",
    "\n",
    "    pred_lgb = np.expm1(models[\"lgbm\"].predict(X))\n",
    "    pred_xgb = np.expm1(models[\"xgb\"].predict(X))\n",
    "    return models[\"w_lgb\"] * pred_lgb + models[\"w_xgb\"] * pred_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9562462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_price_feature(df: pd.DataFrame, k: int = 5):\n",
    "    FEATURES = [\n",
    "    \"begin_lat\",\"begin_lng\",\"end_lat\",\"end_lng\",\n",
    "    \"sec_pred\",\"osrm_km\",\n",
    "    \"hour\",\"dow\",\"month_idx\",\"doy\",\n",
    "    ]\n",
    "\n",
    "    LGB_PARAMS = dict(\n",
    "        objective=\"fair\", \n",
    "        fair_c=1.0,\n",
    "        n_estimators=800, \n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8, \n",
    "        num_leaves=63,\n",
    "        min_data_in_leaf=50, \n",
    "        max_depth=-1,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "\n",
    "    XGB_PARAMS = dict(\n",
    "        n_estimators=800, \n",
    "        learning_rate=0.05,\n",
    "        max_depth=8, \n",
    "        subsample=0.8,\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_jobs=-1, \n",
    "        random_state=SEED,\n",
    "    )\n",
    "\n",
    "    w_lgb = 0.75\n",
    "    w_xgb  = 0.25\n",
    "    assert abs((w_lgb + w_xgb) - 1.0) < 1e-9, \"Blend weights must sum to 1.0\"\n",
    "\n",
    "    need = FEATURES + [\"pay_after_uber_cut\"]\n",
    "\n",
    "    good = df[need].notna().all(axis=1)\n",
    "    work = df.loc[good].copy()\n",
    "\n",
    "    # log target\n",
    "    work[\"log_fare\"] = np.log1p(work[\"pay_after_uber_cut\"].clip(lower=0))\n",
    "\n",
    "    # OOF container\n",
    "    work[\"price_pred\"] = np.nan\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(work), 1):\n",
    "        Xtr, ytr = work.iloc[tr_idx][FEATURES], work.iloc[tr_idx][\"log_fare\"]\n",
    "        Xva      = work.iloc[va_idx][FEATURES]\n",
    "\n",
    "        # LGBM on log target\n",
    "        mdl_lgb = lgb.LGBMRegressor(**LGB_PARAMS)\n",
    "        mdl_lgb.fit(Xtr, ytr)\n",
    "        pred_lgb_log = mdl_lgb.predict(Xva)\n",
    "        pred_lgb = np.expm1(pred_lgb_log)\n",
    "\n",
    "        # XGB on log target\n",
    "        mdl_xgb = XGBRegressor(**XGB_PARAMS)\n",
    "        mdl_xgb.fit(Xtr, ytr)\n",
    "        pred_xgb_log = mdl_xgb.predict(Xva)\n",
    "        pred_xgb = np.expm1(pred_xgb_log)\n",
    "\n",
    "        # Blend in price space\n",
    "        blend = w_lgb * pred_lgb + w_xgb * pred_xgb\n",
    "        work.loc[work.index[va_idx], \"price_pred\"] = blend\n",
    "\n",
    "        print(f\"fold {fold}/{k} done\")\n",
    "\n",
    "\n",
    "    assert work[\"price_pred\"].isna().sum() == 0, \"OOF fill failed!\"\n",
    "\n",
    "\n",
    "    mae  = mean_absolute_error(work[\"pay_after_uber_cut\"], work[\"price_pred\"])\n",
    "    rmse = root_mean_squared_error(work[\"pay_after_uber_cut\"], work[\"price_pred\"])\n",
    "    print(f\"OOF  MAE £{mae:.3f}   RMSE £{rmse:.3f}   on {len(work):,} rows\")\n",
    "\n",
    "    X_all, y_all = work[FEATURES], work[\"log_fare\"]\n",
    "    final_lgb = lgb.LGBMRegressor(**LGB_PARAMS).fit(X_all, y_all)\n",
    "    final_xgb = XGBRegressor(**XGB_PARAMS).fit(X_all, y_all)\n",
    "\n",
    "\n",
    "    PRICE_MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(final_lgb, PRICE_MODEL_DIR / \"price_lgbm_log.joblib\")\n",
    "    joblib.dump(final_xgb, PRICE_MODEL_DIR / \"price_xgb_log.joblib\")\n",
    "    json.dump(\n",
    "        FEATURES,\n",
    "        open(PRICE_MODEL_DIR / \"price_feature_order.json\", \"w\")\n",
    "    )\n",
    "    json.dump(\n",
    "        {\"k\": k, \"mae\": float(mae), \"rmse\": float(rmse),\n",
    "         \"blend_w\": {\"lgbm\": float(w_lgb), \"xgb\": float(w_xgb)},\n",
    "         \"model_type\": \"blend_log_space_models_price_space_blend\"},\n",
    "        open(PRICE_MODEL_DIR / \"metadata.json\", \"w\"), indent=2\n",
    "    )\n",
    "\n",
    "\n",
    "    df = df.copy()\n",
    "    df.loc[work.index, \"price_pred\"] = work[\"price_pred\"]\n",
    "\n",
    "    models = {\"lgbm\": final_lgb, \"xgb\": final_xgb,\n",
    "              \"features\": FEATURES, \"w_lgb\": w_lgb, \"w_xgb\": w_xgb}\n",
    "    return df, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bfce376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1900\n",
      "[LightGBM] [Info] Number of data points in the train set: 128585, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 2.219904\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "fold 1/8 done\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1899\n",
      "[LightGBM] [Info] Number of data points in the train set: 128585, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 2.221269\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "fold 2/8 done\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1898\n",
      "[LightGBM] [Info] Number of data points in the train set: 128585, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 2.220505\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "fold 3/8 done\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1899\n",
      "[LightGBM] [Info] Number of data points in the train set: 128586, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 2.220070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "fold 4/8 done\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1900\n",
      "[LightGBM] [Info] Number of data points in the train set: 128586, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 2.220892\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "fold 5/8 done\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1900\n",
      "[LightGBM] [Info] Number of data points in the train set: 128586, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 2.220132\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "fold 6/8 done\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1899\n",
      "[LightGBM] [Info] Number of data points in the train set: 128586, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 2.220162\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "fold 7/8 done\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1900\n",
      "[LightGBM] [Info] Number of data points in the train set: 128586, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 2.219600\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "fold 8/8 done\n",
      "OOF  MAE £1.628   RMSE £3.161   on 146,955 rows\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1899\n",
      "[LightGBM] [Info] Number of data points in the train set: 146955, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 2.220317\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_row</th>\n",
       "      <th>origin_col</th>\n",
       "      <th>dest_row</th>\n",
       "      <th>dest_col</th>\n",
       "      <th>begin_lat</th>\n",
       "      <th>begin_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>haversine_km</th>\n",
       "      <th>begintrip_timestamp_london</th>\n",
       "      <th>...</th>\n",
       "      <th>trip_distance_miles</th>\n",
       "      <th>trip_distance_km</th>\n",
       "      <th>osrm_sec</th>\n",
       "      <th>osrm_km</th>\n",
       "      <th>dow</th>\n",
       "      <th>month_idx</th>\n",
       "      <th>doy</th>\n",
       "      <th>km_pred</th>\n",
       "      <th>sec_pred</th>\n",
       "      <th>price_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>51.440338</td>\n",
       "      <td>-0.159358</td>\n",
       "      <td>51.456711</td>\n",
       "      <td>-0.191571</td>\n",
       "      <td>2.880576</td>\n",
       "      <td>2016-04-28 17:23:20+01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.789894</td>\n",
       "      <td>4.489888</td>\n",
       "      <td>398.700012</td>\n",
       "      <td>3.4857</td>\n",
       "      <td>3</td>\n",
       "      <td>24196</td>\n",
       "      <td>119</td>\n",
       "      <td>3.625828</td>\n",
       "      <td>664.820351</td>\n",
       "      <td>5.677524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>51.445763</td>\n",
       "      <td>-0.191400</td>\n",
       "      <td>51.474430</td>\n",
       "      <td>-0.167369</td>\n",
       "      <td>3.596283</td>\n",
       "      <td>2016-04-28 17:50:48+01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.236049</td>\n",
       "      <td>5.207903</td>\n",
       "      <td>626.099976</td>\n",
       "      <td>5.0948</td>\n",
       "      <td>3</td>\n",
       "      <td>24196</td>\n",
       "      <td>119</td>\n",
       "      <td>5.318336</td>\n",
       "      <td>955.559975</td>\n",
       "      <td>7.482545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>51.479115</td>\n",
       "      <td>-0.166910</td>\n",
       "      <td>51.490761</td>\n",
       "      <td>-0.183790</td>\n",
       "      <td>1.744453</td>\n",
       "      <td>2016-04-28 18:10:50+01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.491487</td>\n",
       "      <td>2.400309</td>\n",
       "      <td>302.100006</td>\n",
       "      <td>1.9474</td>\n",
       "      <td>3</td>\n",
       "      <td>24196</td>\n",
       "      <td>119</td>\n",
       "      <td>2.202951</td>\n",
       "      <td>542.938647</td>\n",
       "      <td>5.192629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>51.487488</td>\n",
       "      <td>-0.191229</td>\n",
       "      <td>51.502617</td>\n",
       "      <td>-0.199705</td>\n",
       "      <td>1.781674</td>\n",
       "      <td>2016-04-28 18:24:59+01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.642280</td>\n",
       "      <td>2.642988</td>\n",
       "      <td>389.100006</td>\n",
       "      <td>2.6575</td>\n",
       "      <td>3</td>\n",
       "      <td>24196</td>\n",
       "      <td>119</td>\n",
       "      <td>2.887826</td>\n",
       "      <td>690.397036</td>\n",
       "      <td>5.808538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>51.444721</td>\n",
       "      <td>-0.148535</td>\n",
       "      <td>51.502235</td>\n",
       "      <td>-0.186893</td>\n",
       "      <td>6.925133</td>\n",
       "      <td>2016-04-28 21:06:02+01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.204270</td>\n",
       "      <td>13.203459</td>\n",
       "      <td>1175.900024</td>\n",
       "      <td>7.8614</td>\n",
       "      <td>3</td>\n",
       "      <td>24196</td>\n",
       "      <td>119</td>\n",
       "      <td>8.588139</td>\n",
       "      <td>1328.159043</td>\n",
       "      <td>9.898572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin_row  origin_col  dest_row  dest_col  begin_lat  begin_lng  \\\n",
       "0           5          12         7         7  51.440338  -0.159358   \n",
       "1           6           7         9        11  51.445763  -0.191400   \n",
       "2          10          11        12         8  51.479115  -0.166910   \n",
       "3          11           7        13         6  51.487488  -0.191229   \n",
       "4           5          13        13         8  51.444721  -0.148535   \n",
       "\n",
       "     end_lat   end_lng  haversine_km begintrip_timestamp_london  ...  \\\n",
       "0  51.456711 -0.191571      2.880576  2016-04-28 17:23:20+01:00  ...   \n",
       "1  51.474430 -0.167369      3.596283  2016-04-28 17:50:48+01:00  ...   \n",
       "2  51.490761 -0.183790      1.744453  2016-04-28 18:10:50+01:00  ...   \n",
       "3  51.502617 -0.199705      1.781674  2016-04-28 18:24:59+01:00  ...   \n",
       "4  51.502235 -0.186893      6.925133  2016-04-28 21:06:02+01:00  ...   \n",
       "\n",
       "  trip_distance_miles  trip_distance_km     osrm_sec  osrm_km dow  month_idx  \\\n",
       "0            2.789894          4.489888   398.700012   3.4857   3      24196   \n",
       "1            3.236049          5.207903   626.099976   5.0948   3      24196   \n",
       "2            1.491487          2.400309   302.100006   1.9474   3      24196   \n",
       "3            1.642280          2.642988   389.100006   2.6575   3      24196   \n",
       "4            8.204270         13.203459  1175.900024   7.8614   3      24196   \n",
       "\n",
       "   doy   km_pred     sec_pred  price_pred  \n",
       "0  119  3.625828   664.820351    5.677524  \n",
       "1  119  5.318336   955.559975    7.482545  \n",
       "2  119  2.202951   542.938647    5.192629  \n",
       "3  119  2.887826   690.397036    5.808538  \n",
       "4  119  8.588139  1328.159043    9.898572  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, duration_model = build_price_feature(df, k=8)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c18b099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → C:\\Users\\aless\\OneDrive - Nexus365\\Thesis\\driver_data\\combined_path\\new_test\\original\\trips_original_0075_v2_with_predicted_information.parquet\n"
     ]
    }
   ],
   "source": [
    "df.to_parquet(PARQUET_OUT, compression=\"zstd\")\n",
    "print(\"Saved →\", PARQUET_OUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "driver_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
