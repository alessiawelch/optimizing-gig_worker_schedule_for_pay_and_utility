{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "2pX7qk1ts5jK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline      import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model  import LinearRegression, ElasticNetCV\n",
        "from sklearn.neighbors     import KNeighborsRegressor\n",
        "from sklearn.tree          import DecisionTreeRegressor\n",
        "from sklearn.ensemble      import (\n",
        "    GradientBoostingRegressor, AdaBoostRegressor,\n",
        "    RandomForestRegressor, ExtraTreesRegressor\n",
        ")\n",
        "from xgboost               import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics       import mean_absolute_error, root_mean_squared_error\n",
        "import pandas as pd, numpy as np\n",
        "import json, joblib\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "RacCksP5tC1q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading  : C:\\Users\\aless\\OneDrive - Nexus365\\Thesis\\driver_data\\combined_path\\new_test\\original\\trips_original_0075_v2_with_predicted_distance.parquet\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ROOT = Path.cwd().resolve().parents[1]     \n",
        "COMBINED_DIR   = PROJECT_ROOT / \"combined_path\"\n",
        "OG_DIR = COMBINED_DIR / \"new_test\" / \"original\"\n",
        "CELL_FILE_ADDITION = \"original_0075_v2\"\n",
        "\n",
        "\n",
        "PARQUET_PATH    = OG_DIR / f\"trips_{CELL_FILE_ADDITION}_with_predicted_distance.parquet\"\n",
        "#PARQUET_PATH = COMBINED_DIR / f'trips_0075_with_predicted_distance.parquet'\n",
        "\n",
        "\n",
        "print(\"Reading  :\", PARQUET_PATH)\n",
        "\n",
        "SEED = 42\n",
        "EXTENSION = CELL_FILE_ADDITION\n",
        "\n",
        "df = pd.read_parquet(PARQUET_PATH)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "3RXOQqsr-C71"
      },
      "outputs": [],
      "source": [
        "df[\"dow\"]        = df[\"begintrip_timestamp_london\"].dt.dayofweek\n",
        "df[\"month_idx\"]  = (\n",
        "    df[\"begintrip_timestamp_london\"].dt.year * 12 +\n",
        "    df[\"begintrip_timestamp_london\"].dt.month\n",
        ")\n",
        "df[\"doy\"] = df[\"begintrip_timestamp_london\"].dt.dayofyear\n",
        "\n",
        "dow_map = {0:\"Monday\", 1:\"Tuesday\", 2:\"Wednesday\", 3:\"Thursday\",\n",
        "           4:\"Friday\", 5:\"Saturday\", 6:\"Sunday\"}\n",
        "\n",
        "dow_map = {0:\"Monday\", 1:\"Tuesday\", 2:\"Wednesday\", 3:\"Thursday\",\n",
        "           4:\"Friday\", 5:\"Saturday\", 6:\"Sunday\"}\n",
        "df[\"dow_text\"]       = df[\"begintrip_timestamp_london\"].dt.dayofweek.map(dow_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5ywsS4PI-maf"
      },
      "outputs": [],
      "source": [
        "# https://www.tomtom.com/newsroom/explainers-and-insights/london-is-the-worlds-slowest-city/\n",
        "\n",
        "speed_grid = {\n",
        "    \"Sunday\":    [19,20,22,22,24,26,25,25,23,21,19,18,17,16,16,16,16,16,16,17,19,20,20,22],\n",
        "    \"Monday\":    [23,24,25,26,26,26,21,17,15,15,15,15,15,15,16,15,15,15,16,17,19,20,20,22],\n",
        "    \"Tuesday\":   [23,25,25,26,26,26,21,16,14,14,14,14,14,14,15,14,14,14,14,16,18,19,19,21],\n",
        "    \"Wednesday\": [23,24,25,26,26,26,21,16,14,14,14,14,14,14,14,14,14,14,14,16,18,19,19,20],\n",
        "    \"Thursday\":  [22,24,25,26,26,25,21,16,14,14,14,14,14,14,14,14,13,13,14,15,17,18,18,19],\n",
        "    \"Friday\":    [21,22,24,25,26,25,21,17,15,15,15,14,14,14,14,14,14,14,14,15,17,18,17,18],\n",
        "    \"Saturday\":  [19,21,22,23,25,26,25,23,21,19,18,16,16,15,15,15,15,15,15,15,17,17,17,17]\n",
        "}\n",
        "\n",
        "speed_tbl = (\n",
        "    pd.DataFrame(speed_grid,    # index = 0â€¦23\n",
        "                 index=range(24))\n",
        "      .stack()\n",
        "      .reset_index(name=\"kmh\")         # columns: level_0, level_1, kmh\n",
        "      .rename(columns={\"level_0\": \"hour\",   # ðŸ’¡ rename here\n",
        "                       \"level_1\": \"dow_text\"})\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "uE6HJDMctEaJ",
        "outputId": "4e37896e-8141-4df9-c02e-a2e5a3541695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 147,498 rows\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>origin_row</th>\n",
              "      <th>origin_col</th>\n",
              "      <th>dest_row</th>\n",
              "      <th>dest_col</th>\n",
              "      <th>begin_lat</th>\n",
              "      <th>begin_lng</th>\n",
              "      <th>end_lat</th>\n",
              "      <th>end_lng</th>\n",
              "      <th>haversine_km</th>\n",
              "      <th>begintrip_timestamp_london</th>\n",
              "      <th>...</th>\n",
              "      <th>driver_id_offline_online</th>\n",
              "      <th>trip_distance_miles</th>\n",
              "      <th>trip_distance_km</th>\n",
              "      <th>osrm_sec</th>\n",
              "      <th>osrm_km</th>\n",
              "      <th>dow</th>\n",
              "      <th>month_idx</th>\n",
              "      <th>doy</th>\n",
              "      <th>km_pred</th>\n",
              "      <th>dow_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>51.440338</td>\n",
              "      <td>-0.159358</td>\n",
              "      <td>51.456711</td>\n",
              "      <td>-0.191571</td>\n",
              "      <td>2.880576</td>\n",
              "      <td>2016-04-28 17:23:20+01:00</td>\n",
              "      <td>...</td>\n",
              "      <td>03d0deda558765c2fbf485c57117bf2a3537611151fb49441ef9f285092305b6</td>\n",
              "      <td>2.789894</td>\n",
              "      <td>4.489888</td>\n",
              "      <td>398.700012</td>\n",
              "      <td>3.4857</td>\n",
              "      <td>3</td>\n",
              "      <td>24196</td>\n",
              "      <td>119</td>\n",
              "      <td>3.625828</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>51.445763</td>\n",
              "      <td>-0.191400</td>\n",
              "      <td>51.474430</td>\n",
              "      <td>-0.167369</td>\n",
              "      <td>3.596283</td>\n",
              "      <td>2016-04-28 17:50:48+01:00</td>\n",
              "      <td>...</td>\n",
              "      <td>03d0deda558765c2fbf485c57117bf2a3537611151fb49441ef9f285092305b6</td>\n",
              "      <td>3.236049</td>\n",
              "      <td>5.207903</td>\n",
              "      <td>626.099976</td>\n",
              "      <td>5.0948</td>\n",
              "      <td>3</td>\n",
              "      <td>24196</td>\n",
              "      <td>119</td>\n",
              "      <td>5.318336</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>51.479115</td>\n",
              "      <td>-0.166910</td>\n",
              "      <td>51.490761</td>\n",
              "      <td>-0.183790</td>\n",
              "      <td>1.744453</td>\n",
              "      <td>2016-04-28 18:10:50+01:00</td>\n",
              "      <td>...</td>\n",
              "      <td>03d0deda558765c2fbf485c57117bf2a3537611151fb49441ef9f285092305b6</td>\n",
              "      <td>1.491487</td>\n",
              "      <td>2.400309</td>\n",
              "      <td>302.100006</td>\n",
              "      <td>1.9474</td>\n",
              "      <td>3</td>\n",
              "      <td>24196</td>\n",
              "      <td>119</td>\n",
              "      <td>2.202951</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>51.487488</td>\n",
              "      <td>-0.191229</td>\n",
              "      <td>51.502617</td>\n",
              "      <td>-0.199705</td>\n",
              "      <td>1.781674</td>\n",
              "      <td>2016-04-28 18:24:59+01:00</td>\n",
              "      <td>...</td>\n",
              "      <td>03d0deda558765c2fbf485c57117bf2a3537611151fb49441ef9f285092305b6</td>\n",
              "      <td>1.642280</td>\n",
              "      <td>2.642988</td>\n",
              "      <td>389.100006</td>\n",
              "      <td>2.6575</td>\n",
              "      <td>3</td>\n",
              "      <td>24196</td>\n",
              "      <td>119</td>\n",
              "      <td>2.887826</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>51.444721</td>\n",
              "      <td>-0.148535</td>\n",
              "      <td>51.502235</td>\n",
              "      <td>-0.186893</td>\n",
              "      <td>6.925133</td>\n",
              "      <td>2016-04-28 21:06:02+01:00</td>\n",
              "      <td>...</td>\n",
              "      <td>03d0deda558765c2fbf485c57117bf2a3537611151fb49441ef9f285092305b6</td>\n",
              "      <td>8.204270</td>\n",
              "      <td>13.203459</td>\n",
              "      <td>1175.900024</td>\n",
              "      <td>7.8614</td>\n",
              "      <td>3</td>\n",
              "      <td>24196</td>\n",
              "      <td>119</td>\n",
              "      <td>8.588139</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   origin_row  origin_col  dest_row  dest_col  begin_lat  begin_lng  \\\n",
              "0           5          12         7         7  51.440338  -0.159358   \n",
              "1           6           7         9        11  51.445763  -0.191400   \n",
              "2          10          11        12         8  51.479115  -0.166910   \n",
              "3          11           7        13         6  51.487488  -0.191229   \n",
              "4           5          13        13         8  51.444721  -0.148535   \n",
              "\n",
              "     end_lat   end_lng  haversine_km begintrip_timestamp_london  ...  \\\n",
              "0  51.456711 -0.191571      2.880576  2016-04-28 17:23:20+01:00  ...   \n",
              "1  51.474430 -0.167369      3.596283  2016-04-28 17:50:48+01:00  ...   \n",
              "2  51.490761 -0.183790      1.744453  2016-04-28 18:10:50+01:00  ...   \n",
              "3  51.502617 -0.199705      1.781674  2016-04-28 18:24:59+01:00  ...   \n",
              "4  51.502235 -0.186893      6.925133  2016-04-28 21:06:02+01:00  ...   \n",
              "\n",
              "                                           driver_id_offline_online  \\\n",
              "0  03d0deda558765c2fbf485c57117bf2a3537611151fb49441ef9f285092305b6   \n",
              "1  03d0deda558765c2fbf485c57117bf2a3537611151fb49441ef9f285092305b6   \n",
              "2  03d0deda558765c2fbf485c57117bf2a3537611151fb49441ef9f285092305b6   \n",
              "3  03d0deda558765c2fbf485c57117bf2a3537611151fb49441ef9f285092305b6   \n",
              "4  03d0deda558765c2fbf485c57117bf2a3537611151fb49441ef9f285092305b6   \n",
              "\n",
              "   trip_distance_miles  trip_distance_km     osrm_sec osrm_km  dow  month_idx  \\\n",
              "0             2.789894          4.489888   398.700012  3.4857    3      24196   \n",
              "1             3.236049          5.207903   626.099976  5.0948    3      24196   \n",
              "2             1.491487          2.400309   302.100006  1.9474    3      24196   \n",
              "3             1.642280          2.642988   389.100006  2.6575    3      24196   \n",
              "4             8.204270         13.203459  1175.900024  7.8614    3      24196   \n",
              "\n",
              "   doy   km_pred  dow_text  \n",
              "0  119  3.625828  Thursday  \n",
              "1  119  5.318336  Thursday  \n",
              "2  119  2.202951  Thursday  \n",
              "3  119  2.887826  Thursday  \n",
              "4  119  8.588139  Thursday  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f\"Loaded {len(df):,} rows\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tJzXTzf_MKW"
      },
      "source": [
        "Using the predicted km"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Fumw47fStJl0"
      },
      "outputs": [],
      "source": [
        "PREDICTED_DISTANCE_FEATURES = [\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"km_pred\",\n",
        "    \"hour\", \"dow\",   \"month_idx\", \"doy\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "MDNO6yzbtQAb"
      },
      "outputs": [],
      "source": [
        "TARGET_TRUE = \"duration_sec\"\n",
        "X_train_true, X_test_true, y_train_true, y_test_true = train_test_split(\n",
        "    df[PREDICTED_DISTANCE_FEATURES], df[TARGET_TRUE], test_size=0.20, random_state=SEED)\n",
        "\n",
        "results = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi_7q2ISqVKq"
      },
      "source": [
        "Baseline Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KFvka0MtUEU",
        "outputId": "df4e569a-e8e9-489c-97b5-64a0bbdec6b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean duration   1,081.3554\n",
            "Median duration 909.3205\n",
            "Constant-median baseline  MAE 520.9073  RMSE 741.5017\n"
          ]
        }
      ],
      "source": [
        "mean_duration   = df[\"duration_sec\"].mean()\n",
        "median_duration = df[\"duration_sec\"].median()\n",
        "print(f\"Mean duration   {mean_duration:,.4f}\")\n",
        "print(f\"Median duration {median_duration:,.4f}\")\n",
        "\n",
        "# naÃ¯ve constant model = predict training mean for every test row\n",
        "const_pred = np.full_like(y_test_true, fill_value=y_test_true.median())\n",
        "baseline_mae  = mean_absolute_error(y_test_true, const_pred)\n",
        "baseline_rmse = root_mean_squared_error(y_test_true, const_pred)\n",
        "print(f\"Constant-median baseline  MAE {baseline_mae:.4f}  RMSE {baseline_rmse:.4f}\")\n",
        "results.append((\"Constant-median baseline  MAE\", baseline_mae, baseline_rmse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "G1OTvaV0tv_y"
      },
      "outputs": [],
      "source": [
        "MODELS = {\n",
        "    # \"XGBoost\"      : XGBRegressor(\n",
        "    #     n_estimators=800,\n",
        "    #     learning_rate=0.05,\n",
        "    #     max_depth=8,\n",
        "    #     subsample=0.8,\n",
        "    #     objective=\"reg:squarederror\",\n",
        "    #     n_jobs=-1,\n",
        "    #     random_state=SEED,\n",
        "    # ),\n",
        "    \"LightGBM\"     : lgb.LGBMRegressor(\n",
        "        objective       = \"regression_l1\",  # MAE loss for time\n",
        "        n_estimators    = 800,\n",
        "        learning_rate   = 0.05,\n",
        "        num_leaves      = 63,\n",
        "        subsample       = 0.8,\n",
        "        min_data_in_leaf= 50,\n",
        "        max_depth       = -1,\n",
        "        random_state    = SEED,\n",
        "    ),\n",
        "    \"LightGBM quantile\":lgb.LGBMRegressor(\n",
        "        objective=\"quantile\",\n",
        "        alpha=0.5,                 # median\n",
        "        n_estimators=800,\n",
        "        learning_rate=0.05,\n",
        "        num_leaves=63,\n",
        "        min_data_in_leaf=50,\n",
        "        subsample=0.8,\n",
        "        random_state=SEED\n",
        "    )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPMl1GyjtWFy",
        "outputId": "78504270-182c-4218-d0c9-2b24c9875300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006594 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1644\n",
            "[LightGBM] [Info] Number of data points in the train set: 117998, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 910.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "LightGBM         MAE 191.5096 sec   RMSE 359.0806 sec\n",
            "             abs_err        km  hour\n",
            "127692  12645.436783  6.167392    14\n",
            "66292   10022.415885  3.883019    14\n",
            "145447   8485.464543  0.836624    16\n",
            "67316    8039.759657       NaN    22\n",
            "91696    7544.267048  1.866701     2\n",
            "8464     7450.904915  5.188652     0\n",
            "22052    7432.176164  6.826224    20\n",
            "146492   7271.320078  4.719693    13\n",
            "135240   7156.882658  1.648337    12\n",
            "47412    5424.680273  4.120681    16\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005072 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1644\n",
            "[LightGBM] [Info] Number of data points in the train set: 117998, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 910.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "LightGBM quantile  MAE 191.1101 sec   RMSE 359.0092 sec\n",
            "             abs_err        km  hour\n",
            "127692  12602.594664  6.167392    14\n",
            "66292   10034.104152  3.883019    14\n",
            "145447   8524.057314  0.836624    16\n",
            "67316    8091.293184       NaN    22\n",
            "91696    7546.131823  1.866701     2\n",
            "8464     7498.527187  5.188652     0\n",
            "22052    7413.408080  6.826224    20\n",
            "146492   7246.959612  4.719693    13\n",
            "135240   7157.191977  1.648337    12\n",
            "47412    5385.888477  4.120681    16\n"
          ]
        }
      ],
      "source": [
        "for name, model in MODELS.items():\n",
        "    model.fit(X_train_true, y_train_true)\n",
        "    pred = model.predict(X_test_true)\n",
        "    mae  = mean_absolute_error(y_test_true, pred)\n",
        "    rmse = root_mean_squared_error(y_test_true, pred)\n",
        "    results.append((name+\"PREDICTED DISTANCE\", mae, rmse))\n",
        "    print(f\"{name:15}  MAE {mae:5.4f} sec   RMSE {rmse:5.4f} sec\")\n",
        "    resid = pd.DataFrame({\n",
        "    \"abs_err\": (y_test_true - pred).abs(),\n",
        "    \"km\":      X_test_true[\"km_pred\"].values,\n",
        "    \"hour\":    X_test_true[\"hour\"].values,\n",
        "    })\n",
        "    print(resid.nlargest(10, \"abs_err\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55yMUWGOJUrZ"
      },
      "source": [
        "Using only the ORSM Distance Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "-8_ZtdsOJDLk"
      },
      "outputs": [],
      "source": [
        "OSRM_DISTANCE_FEATURES = [\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"osrm_km\",\n",
        "    \"hour\", \"dow\",  \"month_idx\", \"doy\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "1pAsM6OjJQhA"
      },
      "outputs": [],
      "source": [
        "TARGET_TRUE = \"duration_sec\"\n",
        "X_train_true, X_test_true, y_train_true, y_test_true = train_test_split(\n",
        "    df[OSRM_DISTANCE_FEATURES], df[TARGET_TRUE], test_size=0.20, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wea65Z__JNzx",
        "outputId": "a08c9f19-dbb8-4723-cb00-4e0b3cf225be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1644\n",
            "[LightGBM] [Info] Number of data points in the train set: 117998, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 910.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "LightGBM         MAE 192.0907 sec   RMSE 357.7023 sec\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008382 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1644\n",
            "[LightGBM] [Info] Number of data points in the train set: 117998, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 910.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "LightGBM quantile  MAE 192.1519 sec   RMSE 357.6785 sec\n"
          ]
        }
      ],
      "source": [
        "for name, model in MODELS.items():\n",
        "    model.fit(X_train_true, y_train_true)\n",
        "    pred = model.predict(X_test_true)\n",
        "    mae  = mean_absolute_error(y_test_true, pred)\n",
        "    rmse = root_mean_squared_error(y_test_true, pred)\n",
        "    results.append((name+\"OSRM DISTANCE\", mae, rmse))\n",
        "    print(f\"{name:15}  MAE {mae:5.4f} sec   RMSE {rmse:5.4f} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTw2f34TJz1k"
      },
      "source": [
        "Using Only Haversine Distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "D6YDLr3uJilu"
      },
      "outputs": [],
      "source": [
        "HAVERSINE_DISTANCE_FEATURES = [\n",
        "  #  \"origin_row\", \"origin_col\", \"dest_row\", \"dest_col\",\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"haversine_km\",\n",
        "    \"hour\", \"dow\",   \"month_idx\", \"doy\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "_Ze6sbb5J-GJ"
      },
      "outputs": [],
      "source": [
        "TARGET_TRUE = \"duration_sec\"\n",
        "X_train_true, X_test_true, y_train_true, y_test_true = train_test_split(\n",
        "    df[HAVERSINE_DISTANCE_FEATURES], df[TARGET_TRUE], test_size=0.20, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1BvsMQuJsdz",
        "outputId": "3bec4753-c7c1-4233-b264-b90874935dc9"
      },
      "outputs": [],
      "source": [
        "# for name, model in MODELS.items():\n",
        "#     model.fit(X_train_true, y_train_true)\n",
        "#     pred = model.predict(X_test_true)\n",
        "#     mae  = mean_absolute_error(y_test_true, pred)\n",
        "#     rmse = root_mean_squared_error(y_test_true, pred)\n",
        "#     results.append((name+\"HAVERSINE DISTANCE\", mae, rmse))\n",
        "#     print(f\"{name:15}  MAE {mae:5.4f} sec   RMSE {rmse:5.4f} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INZ6DjJ2n-lN"
      },
      "source": [
        "USING NO DISTANCE JUST SECONDS PREDICTED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "rlYnkBnamB6L"
      },
      "outputs": [],
      "source": [
        "OSRM_FEATURES = [\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"osrm_sec\",\n",
        "    \"hour\", \"dow\",   \"month_idx\", \"doy\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "QXHh5f39mKNl"
      },
      "outputs": [],
      "source": [
        "TARGET_TRUE = \"duration_sec\"\n",
        "good = df[\"osrm_sec\"].notna() & df[\"duration_sec\"].notna() & df[\"km_pred\"].notna()\n",
        "work = df.loc[good].copy()                     # 140 k â†’ e.g. 132 k rows\n",
        "\n",
        "X_train_true, X_test_true, y_train_true, y_test_true = train_test_split(\n",
        "    work[OSRM_FEATURES], work[TARGET_TRUE], test_size=0.20, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMaxI5uJmOOe",
        "outputId": "32d47b7b-fc76-489a-cd77-39304e2cc336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002069 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1645\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 909.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "LightGBM         MAE 190.9998 sec   RMSE 350.1140 sec\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002316 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1645\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 909.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "LightGBM quantile  MAE 191.0235 sec   RMSE 349.8539 sec\n"
          ]
        }
      ],
      "source": [
        "for name, model in MODELS.items():\n",
        "    model.fit(X_train_true, y_train_true)\n",
        "    pred = model.predict(X_test_true)\n",
        "    mae  = mean_absolute_error(y_test_true, pred)\n",
        "    rmse = root_mean_squared_error(y_test_true, pred)\n",
        "    results.append((name+\"OSRM SECONDS\", mae, rmse))\n",
        "    print(f\"{name:15}  MAE {mae:5.4f} sec   RMSE {rmse:5.4f} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pMNZNuQogwv"
      },
      "source": [
        "OSRM SECONDS and KM Predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "6DileHHAoFau"
      },
      "outputs": [],
      "source": [
        "OSRM_PRED_FEATURES = [\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"osrm_sec\", \"km_pred\",\n",
        "    \"hour\", \"dow\",   \"month_idx\", \"doy\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "lRgdLjGCoJov"
      },
      "outputs": [],
      "source": [
        "TARGET_TRUE = \"duration_sec\"\n",
        "good = df[\"osrm_sec\"].notna() & df[\"duration_sec\"].notna() & df[\"km_pred\"].notna()\n",
        "work = df.loc[good].copy()                     # 140 k â†’ e.g. 132 k rows\n",
        "\n",
        "X_train_true, X_test_true, y_train_true, y_test_true = train_test_split(\n",
        "    work[OSRM_PRED_FEATURES], work[TARGET_TRUE], test_size=0.20, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Le3jreYoaOM",
        "outputId": "aea5ac54-78cc-4a74-f8c1-13709521d632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007691 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1900\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 909.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "LightGBM         MAE 190.6059 sec   RMSE 349.4547 sec\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006714 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1900\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 909.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "LightGBM quantile  MAE 190.6752 sec   RMSE 349.6670 sec\n"
          ]
        }
      ],
      "source": [
        "for name, model in MODELS.items():\n",
        "    model.fit(X_train_true, y_train_true)\n",
        "    pred = model.predict(X_test_true)\n",
        "    mae  = mean_absolute_error(y_test_true, pred)\n",
        "    rmse = root_mean_squared_error(y_test_true, pred)\n",
        "    results.append((name+\"OSRM SECONDS & PREDICTED\", mae, rmse))\n",
        "    print(f\"{name:15}  MAE {mae:5.4f} sec   RMSE {rmse:5.4f} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fipqEZGzo2bk"
      },
      "source": [
        "OSRM SECONDS and OSRM Predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "pf5e4R6tovPx"
      },
      "outputs": [],
      "source": [
        "OSRM_PRED_FEATURES = [\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"osrm_sec\", \"osrm_km\",\n",
        "    \"hour\", \"dow\",   \"month_idx\", \"doy\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "TG33zuFaovPy"
      },
      "outputs": [],
      "source": [
        "TARGET_TRUE = \"duration_sec\"\n",
        "good = df[\"osrm_sec\"].notna() & df[\"duration_sec\"].notna() & df[\"km_pred\"].notna()\n",
        "work = df.loc[good].copy()                     # 140 k â†’ e.g. 132 k rows\n",
        "\n",
        "X_train_true, X_test_true, y_train_true, y_test_true = train_test_split(\n",
        "    work[OSRM_PRED_FEATURES], work[TARGET_TRUE], test_size=0.20, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_UoFpceovPz",
        "outputId": "5abc6a20-2cc1-458b-ac90-b1d2d83b6db1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007844 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1900\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 909.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "LightGBM         MAE 190.7554 sec   RMSE 349.5183 sec\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008549 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1900\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 909.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "LightGBM quantile  MAE 190.5008 sec   RMSE 349.4414 sec\n"
          ]
        }
      ],
      "source": [
        "for name, model in MODELS.items():\n",
        "    model.fit(X_train_true, y_train_true)\n",
        "    pred = model.predict(X_test_true)\n",
        "    mae  = mean_absolute_error(y_test_true, pred)\n",
        "    rmse = root_mean_squared_error(y_test_true, pred)\n",
        "    results.append((name+\"OSRM SECONDS & OSRM KM\", mae, rmse))\n",
        "    print(f\"{name:15}  MAE {mae:5.4f} sec   RMSE {rmse:5.4f} sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "OSRM_PRED_FEATURES = [\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"osrm_sec\", \"osrm_km\", \"km_pred\",\n",
        "    \"hour\", \"dow\",   \"month_idx\", \"doy\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "TARGET_TRUE = \"duration_sec\"\n",
        "good = df[\"osrm_sec\"].notna() & df[\"duration_sec\"].notna() & df[\"km_pred\"].notna()\n",
        "work = df.loc[good].copy()                     # 140 k â†’ e.g. 132 k rows\n",
        "\n",
        "X_train_true, X_test_true, y_train_true, y_test_true = train_test_split(\n",
        "    work[OSRM_PRED_FEATURES], work[TARGET_TRUE], test_size=0.20, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008500 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2155\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 909.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "LightGBM         MAE 190.4787 sec   RMSE 349.4277 sec\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001816 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2155\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 909.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "LightGBM quantile  MAE 190.6382 sec   RMSE 349.5403 sec\n"
          ]
        }
      ],
      "source": [
        "for name, model in MODELS.items():\n",
        "    model.fit(X_train_true, y_train_true)\n",
        "    pred = model.predict(X_test_true)\n",
        "    mae  = mean_absolute_error(y_test_true, pred)\n",
        "    rmse = root_mean_squared_error(y_test_true, pred)\n",
        "    results.append((name+\"OSRM SECONDS & OSRM KM & KM PRED\", mae, rmse))\n",
        "    print(f\"{name:15}  MAE {mae:5.4f} sec   RMSE {rmse:5.4f} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLUT62f9Anqy"
      },
      "source": [
        "Using the OSRM Time Calculated by the OSRM Route"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikgNa3LBihJJ",
        "outputId": "ef59e25f-9a9b-4015-822d-cd883d2f99f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OSRM coverage: 100.0%  (147,482/147,498)\n",
            "MAE  363.6 sec   RMSE  562.8 sec\n"
          ]
        }
      ],
      "source": [
        "mask = df[\"osrm_sec\"].notna()            # keep only rows with a value\n",
        "coverage = mask.mean() * 100\n",
        "print(f\"OSRM coverage: {coverage:.1f}%  ({mask.sum():,}/{len(df):,})\")\n",
        "\n",
        "mae  = mean_absolute_error(df.loc[mask, \"duration_sec\"],\n",
        "                           df.loc[mask, \"osrm_sec\"])\n",
        "rmse = root_mean_squared_error(df.loc[mask, \"duration_sec\"],\n",
        "                          df.loc[mask, \"osrm_sec\"])\n",
        "\n",
        "print(f\"MAE  {mae:.1f} sec   RMSE  {rmse:.1f} sec\")\n",
        "results.append((\"OSRM Seconds no change\", mae, rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2co-DEuAnWv"
      },
      "source": [
        "Using a Congestion Ratio to Adjust OSRM Time Using the Predicted KM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe2m-49vm0xF",
        "outputId": "48bbce0b-88b2-4db2-8ed7-76c1ef980341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on 146,955 clean rows (coverage 99.6%)\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007780 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1645\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 1.378498\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "Ratio Duration OSRM MAE  189.2 sec   RMSE  348.6 sec\n",
            "\n",
            "ðŸ”Ž  Top features (gain normalised):\n",
            "end_lng      14.55\n",
            "begin_lng    14.26\n",
            "begin_lat    13.72\n",
            "end_lat      13.55\n",
            "doy          11.51\n",
            "km_pred       9.89\n",
            "month_idx     8.88\n",
            "hour          8.70\n",
            "dow           4.94\n",
            "Name: gain, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "good = df[\"osrm_sec\"].notna() & df[\"duration_sec\"].notna() & df[\"km_pred\"].notna()\n",
        "\n",
        "work = df.loc[good].copy()                     # 140 k â†’ e.g. 132 k rows\n",
        "work[\"cong_ratio\"] = work[\"duration_sec\"] / work[\"osrm_sec\"]\n",
        "\n",
        "print(f\"Training on {len(work):,} clean rows \"\n",
        "      f\"(coverage {len(work)/len(df):.1%})\")\n",
        "\n",
        "# â”€â”€ 2. Features & target â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FEATURES_RATIO = [\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"km_pred\",\n",
        "    \"hour\",\"dow\", \"month_idx\",\"doy\"\n",
        "]\n",
        "TARGET_RATIO = \"cong_ratio\"\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    work[FEATURES_RATIO], work[TARGET_RATIO], test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "# â”€â”€ 3. Train LightGBM on ratio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ratio_model = lgb.LGBMRegressor(\n",
        "        objective       = \"regression_l1\",  # MAE loss for time\n",
        "        n_estimators    = 800,\n",
        "        learning_rate   = 0.05,\n",
        "        num_leaves      = 63,\n",
        "        subsample       = 0.8,\n",
        "        min_data_in_leaf= 50,\n",
        "        max_depth       = -1,\n",
        "        random_state    = SEED,\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "# â”€â”€ 4. Predict durations for the test split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "pred_ratio    = ratio_model.predict(X_test)\n",
        "dur_pred_test = work.loc[X_test.index, \"osrm_sec\"] * pred_ratio\n",
        "dur_true_test = work.loc[X_test.index, \"duration_sec\"]\n",
        "\n",
        "mae  = mean_absolute_error(dur_true_test, dur_pred_test)\n",
        "rmse = root_mean_squared_error(dur_true_test, dur_pred_test)\n",
        "\n",
        "print(f\"Ratio Duration OSRM MAE  {mae:.1f} sec   RMSE  {rmse:.1f} sec\")\n",
        "results.append((\"Ratio OSRM Duration using Predicted km\", mae, rmse))\n",
        "\n",
        "# X_train already contains the columns in the order LightGBM saw them\n",
        "fi = (pd.Series(ratio_model.feature_importances_,\n",
        "                index=X_train.columns,\n",
        "                name=\"gain\")\n",
        "        .sort_values(ascending=False))\n",
        "\n",
        "print(\"\\nðŸ”Ž  Top features (gain normalised):\")\n",
        "print((fi / fi.sum() * 100).round(2).head(20))   # show top-20 %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on 146,955 clean rows (coverage 99.6%)\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008659 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2155\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 1.378498\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "Ratio Duration All 3 OSRM MAE  189.0 sec   RMSE  347.4 sec\n",
            "\n",
            "ðŸ”Ž  Top features (gain normalised):\n",
            "begin_lat    12.97\n",
            "end_lat      12.85\n",
            "end_lng      12.57\n",
            "begin_lng    12.42\n",
            "doy          10.45\n",
            "month_idx     8.65\n",
            "hour          8.34\n",
            "osrm_sec      7.31\n",
            "osrm_km       5.08\n",
            "km_pred       4.90\n",
            "dow           4.46\n",
            "Name: gain, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "good = df[\"osrm_sec\"].notna() & df[\"duration_sec\"].notna() & df[\"km_pred\"].notna()\n",
        "\n",
        "work = df.loc[good].copy()                     # 140 k â†’ e.g. 132 k rows\n",
        "work[\"cong_ratio\"] = work[\"duration_sec\"] / work[\"osrm_sec\"]\n",
        "\n",
        "print(f\"Training on {len(work):,} clean rows \"\n",
        "      f\"(coverage {len(work)/len(df):.1%})\")\n",
        "\n",
        "# â”€â”€ 2. Features & target â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FEATURES_RATIO = [\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"km_pred\", \"osrm_km\", \"osrm_sec\",\n",
        "    \"hour\",\"dow\", \"month_idx\",\"doy\"\n",
        "]\n",
        "TARGET_RATIO = \"cong_ratio\"\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    work[FEATURES_RATIO], work[TARGET_RATIO], test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "# â”€â”€ 3. Train LightGBM on ratio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ratio_model = lgb.LGBMRegressor(\n",
        "        objective       = \"regression_l1\",  # MAE loss for time\n",
        "        n_estimators    = 800,\n",
        "        learning_rate   = 0.05,\n",
        "        num_leaves      = 63,\n",
        "        subsample       = 0.8,\n",
        "        min_data_in_leaf= 50,\n",
        "        max_depth       = -1,\n",
        "        random_state    = SEED,\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "# â”€â”€ 4. Predict durations for the test split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "pred_ratio    = ratio_model.predict(X_test)\n",
        "dur_pred_test = work.loc[X_test.index, \"osrm_sec\"] * pred_ratio\n",
        "dur_true_test = work.loc[X_test.index, \"duration_sec\"]\n",
        "\n",
        "mae  = mean_absolute_error(dur_true_test, dur_pred_test)\n",
        "rmse = root_mean_squared_error(dur_true_test, dur_pred_test)\n",
        "\n",
        "print(f\"Ratio Duration All 3 OSRM MAE  {mae:.1f} sec   RMSE  {rmse:.1f} sec\")\n",
        "results.append((\"Ratio OSRM Duration using all 3\", mae, rmse))\n",
        "\n",
        "# X_train already contains the columns in the order LightGBM saw them\n",
        "fi = (pd.Series(ratio_model.feature_importances_,\n",
        "                index=X_train.columns,\n",
        "                name=\"gain\")\n",
        "        .sort_values(ascending=False))\n",
        "\n",
        "print(\"\\nðŸ”Ž  Top features (gain normalised):\")\n",
        "print((fi / fi.sum() * 100).round(2).head(20))   # show top-20 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaTnzxpDKTgk"
      },
      "source": [
        "Using a Congestion Ratio to Adjust OSRM Time and only using the OSRM Distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FFLcR23KJmG",
        "outputId": "a0e996b5-7ca9-41b5-c9e1-8c14c1e18a07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on 146,955 clean rows (coverage 99.6%)\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002584 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1645\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 1.378498\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "Ratio Duration OSRM MAE  189.1 sec   RMSE  346.8 sec\n",
            "\n",
            "ðŸ”Ž  Top features (gain normalised):\n",
            "begin_lng    14.21\n",
            "begin_lat    14.19\n",
            "end_lng      14.16\n",
            "end_lat      13.95\n",
            "doy          11.16\n",
            "osrm_km      10.79\n",
            "month_idx     8.52\n",
            "hour          8.37\n",
            "dow           4.67\n",
            "Name: gain, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "good = df[\"osrm_sec\"].notna() & df[\"duration_sec\"].notna() & df[\"km_pred\"].notna()\n",
        "\n",
        "work = df.loc[good].copy()                     # 140 k â†’ e.g. 132 k rows\n",
        "work[\"cong_ratio\"] = work[\"duration_sec\"] / work[\"osrm_sec\"]\n",
        "\n",
        "print(f\"Training on {len(work):,} clean rows \"\n",
        "      f\"(coverage {len(work)/len(df):.1%})\")\n",
        "\n",
        "# â”€â”€ 2. Features & target â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FEATURES_RATIO = [\n",
        "   # \"origin_row\",\"origin_col\",\"dest_row\",\"dest_col\",\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"osrm_km\",          # or haversine_km\n",
        "    \"hour\",\"dow\", \"month_idx\",\"doy\"\n",
        "]\n",
        "TARGET_RATIO = \"cong_ratio\"\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    work[FEATURES_RATIO], work[TARGET_RATIO], test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "# â”€â”€ 3. Train LightGBM on ratio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ratio_model = lgb.LGBMRegressor(\n",
        "        objective       = \"regression_l1\",  # MAE loss for time\n",
        "        n_estimators    = 800,\n",
        "        learning_rate   = 0.05,\n",
        "        num_leaves      = 63,\n",
        "        subsample       = 0.8,\n",
        "        min_data_in_leaf= 50,\n",
        "        max_depth       = -1,\n",
        "        random_state    = SEED,\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "# â”€â”€ 4. Predict durations for the test split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "pred_ratio    = ratio_model.predict(X_test)\n",
        "dur_pred_test = work.loc[X_test.index, \"osrm_sec\"] * pred_ratio\n",
        "dur_true_test = work.loc[X_test.index, \"duration_sec\"]\n",
        "\n",
        "mae  = mean_absolute_error(dur_true_test, dur_pred_test)\n",
        "rmse = root_mean_squared_error(dur_true_test, dur_pred_test)\n",
        "\n",
        "print(f\"Ratio Duration OSRM MAE  {mae:.1f} sec   RMSE  {rmse:.1f} sec\")\n",
        "results.append((\"Ratio OSRM Duration using OSRM km\", mae, rmse))\n",
        "\n",
        "\n",
        "fi = (pd.Series(ratio_model.feature_importances_,\n",
        "                index=X_train.columns,\n",
        "                name=\"gain\")\n",
        "        .sort_values(ascending=False))\n",
        "\n",
        "print(\"\\nðŸ”Ž  Top features (gain normalised):\")\n",
        "print((fi / fi.sum() * 100).round(2).head(20))   # show top-20 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcNlGaW4IX9m"
      },
      "source": [
        "Using London Average Drive Speed and Predicted KM to Engineer Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1UqtQrL0wNS",
        "outputId": "75411678-4cfc-4101-883d-78b7db98b2ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coverage after merge: 100.00000%\n"
          ]
        }
      ],
      "source": [
        "df = df.drop(columns=\"kmh\", errors=\"ignore\")\n",
        "df = df.merge(speed_tbl, on=[\"hour\", \"dow_text\"], how=\"left\")\n",
        "\n",
        "missing = df[\"kmh\"].isna().mean()\n",
        "print(f\"Coverage after merge: {(1-missing):.5%}\")\n",
        "\n",
        "df[\"eng_sec_pred\"] = df[\"km_pred\"] / df[\"kmh\"] * 3600\n",
        "df[\"eng_sec_osrm\"] = df[\"osrm_km\"] / df[\"kmh\"] * 3600\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I--Xaklf1i-1",
        "outputId": "bbf03cbc-89b9-4377-b873-4fb5bff28311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OSRM coverage: 99.6%  (146,955/147,498)\n",
            "Engineered Seconds with Traffic and Predicted Distance no ML  296.2 sec   RMSE  472.9 sec\n"
          ]
        }
      ],
      "source": [
        "mask = df[\"eng_sec_pred\"].notna()            # keep only rows with a value\n",
        "coverage = mask.mean() * 100\n",
        "print(f\"OSRM coverage: {coverage:.1f}%  ({mask.sum():,}/{len(df):,})\")\n",
        "\n",
        "mae  = mean_absolute_error(df.loc[mask, \"duration_sec\"],\n",
        "                           df.loc[mask, \"eng_sec_pred\"])\n",
        "rmse = root_mean_squared_error(df.loc[mask, \"duration_sec\"],\n",
        "                          df.loc[mask, \"eng_sec_pred\"])\n",
        "\n",
        "print(f\"Engineered Seconds with Traffic and Predicted Distance no ML  {mae:.1f} sec   RMSE  {rmse:.1f} sec\")\n",
        "results.append((\"Engineered Seconds with Traffic and Predicted Distance no ML \", mae, rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YniCMIuGjYzR"
      },
      "source": [
        "Using London Average Drive Speed and OSRM KM to Engineer Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHREzFfrjDER",
        "outputId": "354197fc-5cfe-421e-c42e-31dc67e66d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OSRM coverage: 100.0%  (147,482/147,498)\n",
            "Engineered Seconds with Traffic and OSRM Distance no ML  283.5 sec   RMSE  467.0 sec\n"
          ]
        }
      ],
      "source": [
        "mask = df[\"eng_sec_osrm\"].notna()            # keep only rows with a value\n",
        "coverage = mask.mean() * 100\n",
        "print(f\"OSRM coverage: {coverage:.1f}%  ({mask.sum():,}/{len(df):,})\")\n",
        "\n",
        "mae  = mean_absolute_error(df.loc[mask, \"duration_sec\"],\n",
        "                           df.loc[mask, \"eng_sec_osrm\"])\n",
        "rmse = root_mean_squared_error(df.loc[mask, \"duration_sec\"],\n",
        "                          df.loc[mask, \"eng_sec_osrm\"])\n",
        "\n",
        "print(f\"Engineered Seconds with Traffic and OSRM Distance no ML  {mae:.1f} sec   RMSE  {rmse:.1f} sec\")\n",
        "results.append((\"Engineered Seconds with Traffic and OSRM Distance no ML \", mae, rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6OWKEBvIwLR"
      },
      "source": [
        "Engineered Time using Pred KM & Traffic - Feature includes Predicted KM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anW129EO5j4P",
        "outputId": "996a6f17-c188-4ea4-cddb-bc1f471bc0f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on 146,955 clean rows (coverage 99.6%)\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007121 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1645\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 0.890117\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "Duration model  MAE 189.7 s   RMSE 347.5 s\n",
            "\n",
            "ðŸ”Ž  Top features (gain normalised):\n",
            "begin_lat    13.99\n",
            "begin_lng    13.88\n",
            "end_lat      13.36\n",
            "end_lng      13.29\n",
            "doy          11.62\n",
            "km_pred      10.37\n",
            "hour          9.85\n",
            "month_idx     8.74\n",
            "dow           4.89\n",
            "Name: gain, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "good = df[\"eng_sec_pred\"].notna() & df[\"duration_sec\"].notna()\n",
        "work = df.loc[good].copy()\n",
        "work[\"cong_ratio\"] = work[\"duration_sec\"] / work[\"eng_sec_pred\"]\n",
        "\n",
        "print(f\"Training on {len(work):,} clean rows \"\n",
        "      f\"(coverage {len(work)/len(df):.1%})\")\n",
        "\n",
        "# â”€â”€ 2. Features & target â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FEATURES_RATIO = [\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"km_pred\",          # or haversine_km\n",
        "    \"hour\",\"dow\", \"month_idx\",\"doy\"\n",
        "]\n",
        "TARGET_RATIO = \"cong_ratio\"\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    work[FEATURES_RATIO], work[TARGET_RATIO], test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "# â”€â”€ 3. Train LightGBM on ratio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ratio_model = lgb.LGBMRegressor(\n",
        "        objective       = \"regression_l1\",  # MAE loss for time\n",
        "        n_estimators    = 800,\n",
        "        learning_rate   = 0.05,\n",
        "        num_leaves      = 63,\n",
        "        subsample       = 0.8,\n",
        "        min_data_in_leaf= 50,\n",
        "        max_depth       = -1,\n",
        "        random_state    = SEED,\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "# â”€â”€ 4. Predict durations for the test split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "pred_ratio    = ratio_model.predict(X_test)\n",
        "dur_pred_test = work.loc[X_test.index, \"eng_sec_pred\"] * pred_ratio\n",
        "dur_true_test = work.loc[X_test.index, \"duration_sec\"]\n",
        "\n",
        "mae  = mean_absolute_error(dur_true_test, dur_pred_test)\n",
        "rmse = root_mean_squared_error(dur_true_test, dur_pred_test)\n",
        "\n",
        "print(f\"Duration model  MAE {mae:.1f} s   RMSE {rmse:.1f} s\")\n",
        "results.append((\"Ratio Engineered Time using Pred KM & Traffic - Feature includes Predicted KM\", mae, rmse))\n",
        "\n",
        "fi = (pd.Series(ratio_model.feature_importances_,\n",
        "                index=X_train.columns,\n",
        "                name=\"gain\")\n",
        "        .sort_values(ascending=False))\n",
        "\n",
        "print(\"\\nðŸ”Ž  Top features (gain normalised):\")\n",
        "print((fi / fi.sum() * 100).round(2).head(20))   # show top-20 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh6qdUVTj9Eg"
      },
      "source": [
        "Ratio Engineered Time using OSRM KM & Traffic - Feature includes Predicted KM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHEg8yEEkBCR",
        "outputId": "f28c14d8-9e45-4b2f-9e01-1b54ef49d957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on 147,482 clean rows (coverage 100.0%)\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006756 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1644\n",
            "[LightGBM] [Info] Number of data points in the train set: 117985, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 0.950617\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "Duration model  MAE 206.3 s   RMSE 1306.5 s\n",
            "\n",
            "ðŸ”Ž  Top features (gain normalised):\n",
            "begin_lat    14.09\n",
            "end_lng      13.42\n",
            "end_lat      13.40\n",
            "begin_lng    13.19\n",
            "km_pred      11.89\n",
            "doy          11.30\n",
            "hour          9.39\n",
            "month_idx     8.54\n",
            "dow           4.78\n",
            "Name: gain, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "good = df[\"eng_sec_osrm\"].notna() & df[\"duration_sec\"].notna()\n",
        "work = df.loc[good].copy()\n",
        "work[\"cong_ratio\"] = work[\"duration_sec\"] / work[\"eng_sec_osrm\"]\n",
        "\n",
        "print(f\"Training on {len(work):,} clean rows \"\n",
        "      f\"(coverage {len(work)/len(df):.1%})\")\n",
        "\n",
        "# â”€â”€ 2. Features & target â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FEATURES_RATIO = [\n",
        "   # \"origin_row\",\"origin_col\",\"dest_row\",\"dest_col\",\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"km_pred\",          # or haversine_km\n",
        "    \"hour\",\"dow\", \"month_idx\",\"doy\"\n",
        "]\n",
        "TARGET_RATIO = \"cong_ratio\"\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    work[FEATURES_RATIO], work[TARGET_RATIO], test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "# â”€â”€ 3. Train LightGBM on ratio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ratio_model = lgb.LGBMRegressor(\n",
        "        objective       = \"regression_l1\",  # MAE loss for time\n",
        "        n_estimators    = 800,\n",
        "        learning_rate   = 0.05,\n",
        "        num_leaves      = 63,\n",
        "        subsample       = 0.8,\n",
        "        min_data_in_leaf= 50,\n",
        "        max_depth       = -1,\n",
        "        random_state    = SEED,\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "# â”€â”€ 4. Predict durations for the test split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "pred_ratio    = ratio_model.predict(X_test)\n",
        "dur_pred_test = work.loc[X_test.index, \"eng_sec_osrm\"] * pred_ratio\n",
        "dur_true_test = work.loc[X_test.index, \"duration_sec\"]\n",
        "\n",
        "mae  = mean_absolute_error(dur_true_test, dur_pred_test)\n",
        "rmse = root_mean_squared_error(dur_true_test, dur_pred_test)\n",
        "\n",
        "print(f\"Duration model  MAE {mae:.1f} s   RMSE {rmse:.1f} s\")\n",
        "results.append((\"Ratio Engineered Time using OSRM KM & Traffic - Feature includes Predicted KM\", mae, rmse))\n",
        "\n",
        "fi = (pd.Series(ratio_model.feature_importances_,\n",
        "                index=X_train.columns,\n",
        "                name=\"gain\")\n",
        "        .sort_values(ascending=False))\n",
        "\n",
        "print(\"\\nðŸ”Ž  Top features (gain normalised):\")\n",
        "print((fi / fi.sum() * 100).round(2).head(20))   # show top-20 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM0-tx-HKknS"
      },
      "source": [
        "Ratio Engineered Time using Pred KM & Traffic - Feature includes OSRM KM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "427OPgsMKdpp",
        "outputId": "87e177da-032d-4937-9201-fffd8c9c6896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on 146,955 clean rows (coverage 99.6%)\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007209 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1645\n",
            "[LightGBM] [Info] Number of data points in the train set: 117564, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 0.890117\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "Duration model  MAE 189.8 s   RMSE 347.2 s\n",
            "\n",
            "ðŸ”Ž  Top features (gain normalised):\n",
            "begin_lat    13.84\n",
            "begin_lng    13.60\n",
            "end_lng      13.34\n",
            "end_lat      13.15\n",
            "doy          11.68\n",
            "osrm_km      10.28\n",
            "hour         10.22\n",
            "month_idx     9.04\n",
            "dow           4.85\n",
            "Name: gain, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "good = df[\"eng_sec_pred\"].notna() & df[\"duration_sec\"].notna()\n",
        "work = df.loc[good].copy()\n",
        "work[\"cong_ratio\"] = work[\"duration_sec\"] / work[\"eng_sec_pred\"]\n",
        "\n",
        "print(f\"Training on {len(work):,} clean rows \"\n",
        "      f\"(coverage {len(work)/len(df):.1%})\")\n",
        "\n",
        "# â”€â”€ 2. Features & target â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FEATURES_RATIO = [\n",
        "   # \"origin_row\",\"origin_col\",\"dest_row\",\"dest_col\",\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"osrm_km\",          # or haversine_km\n",
        "    \"hour\",\"dow\", \"month_idx\",\"doy\"\n",
        "]\n",
        "TARGET_RATIO = \"cong_ratio\"\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    work[FEATURES_RATIO], work[TARGET_RATIO], test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "# â”€â”€ 3. Train LightGBM on ratio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ratio_model = lgb.LGBMRegressor(\n",
        "        objective       = \"regression_l1\",  # MAE loss for time\n",
        "        n_estimators    = 800,\n",
        "        learning_rate   = 0.05,\n",
        "        num_leaves      = 63,\n",
        "        subsample       = 0.8,\n",
        "        min_data_in_leaf= 50,\n",
        "        max_depth       = -1,\n",
        "        random_state    = SEED,\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "# â”€â”€ 4. Predict durations for the test split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "pred_ratio    = ratio_model.predict(X_test)\n",
        "dur_pred_test = work.loc[X_test.index, \"eng_sec_pred\"] * pred_ratio\n",
        "dur_true_test = work.loc[X_test.index, \"duration_sec\"]\n",
        "\n",
        "mae  = mean_absolute_error(dur_true_test, dur_pred_test)\n",
        "rmse = root_mean_squared_error(dur_true_test, dur_pred_test)\n",
        "\n",
        "print(f\"Duration model  MAE {mae:.1f} s   RMSE {rmse:.1f} s\")\n",
        "results.append((\"Ratio Engineered Time using Pred KM & Traffic - Feature includes OSRM KM\", mae, rmse))\n",
        "\n",
        "fi = (pd.Series(ratio_model.feature_importances_,\n",
        "                index=X_train.columns,\n",
        "                name=\"gain\")\n",
        "        .sort_values(ascending=False))\n",
        "\n",
        "print(\"\\nðŸ”Ž  Top features (gain normalised):\")\n",
        "print((fi / fi.sum() * 100).round(2).head(20))   # show top-20 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_xYWSGhkv-l"
      },
      "source": [
        "Ratio Engineered Time using OSRM KM & Traffic - Feature includes OSRM KM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI8vmRUlkq7a",
        "outputId": "df231946-fc8a-4cd6-e390-6006b428c4fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on 147,482 clean rows (coverage 100.0%)\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1644\n",
            "[LightGBM] [Info] Number of data points in the train set: 117985, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 0.950617\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "Duration model  MAE 206.3 s   RMSE 1306.5 s\n",
            "\n",
            "ðŸ”Ž  Top features (gain normalised):\n",
            "begin_lat    14.09\n",
            "end_lng      13.42\n",
            "end_lat      13.40\n",
            "begin_lng    13.19\n",
            "km_pred      11.89\n",
            "doy          11.30\n",
            "hour          9.39\n",
            "month_idx     8.54\n",
            "dow           4.78\n",
            "Name: gain, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "good = df[\"eng_sec_osrm\"].notna() & df[\"duration_sec\"].notna()\n",
        "work = df.loc[good].copy()\n",
        "work[\"cong_ratio\"] = work[\"duration_sec\"] / work[\"eng_sec_osrm\"]\n",
        "\n",
        "print(f\"Training on {len(work):,} clean rows \"\n",
        "      f\"(coverage {len(work)/len(df):.1%})\")\n",
        "\n",
        "# â”€â”€ 2. Features & target â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "FEATURES_RATIO = [\n",
        "  #  \"origin_row\",\"origin_col\",\"dest_row\",\"dest_col\",\n",
        "    \"begin_lat\",  \"begin_lng\",  \"end_lat\",  \"end_lng\",\n",
        "    \"km_pred\",          # or haversine_km\n",
        "    \"hour\",\"dow\", \"month_idx\",\"doy\"\n",
        "]\n",
        "TARGET_RATIO = \"cong_ratio\"\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    work[FEATURES_RATIO], work[TARGET_RATIO], test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "# â”€â”€ 3. Train LightGBM on ratio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ratio_model = lgb.LGBMRegressor(\n",
        "        objective       = \"regression_l1\",  # MAE loss for time\n",
        "        n_estimators    = 800,\n",
        "        learning_rate   = 0.05,\n",
        "        num_leaves      = 63,\n",
        "        subsample       = 0.8,\n",
        "        min_data_in_leaf= 50,\n",
        "        max_depth       = -1,\n",
        "        random_state    = SEED,\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "# â”€â”€ 4. Predict durations for the test split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "pred_ratio    = ratio_model.predict(X_test)\n",
        "dur_pred_test = work.loc[X_test.index, \"eng_sec_osrm\"] * pred_ratio\n",
        "dur_true_test = work.loc[X_test.index, \"duration_sec\"]\n",
        "\n",
        "mae  = mean_absolute_error(dur_true_test, dur_pred_test)\n",
        "rmse = root_mean_squared_error(dur_true_test, dur_pred_test)\n",
        "\n",
        "print(f\"Duration model  MAE {mae:.1f} s   RMSE {rmse:.1f} s\")\n",
        "results.append((\"Ratio Engineered Time using OSRM KM & Traffic - Feature includes OSRM KM\", mae, rmse))\n",
        "\n",
        "fi = (pd.Series(ratio_model.feature_importances_,\n",
        "                index=X_train.columns,\n",
        "                name=\"gain\")\n",
        "        .sort_values(ascending=False))\n",
        "\n",
        "print(\"\\nðŸ”Ž  Top features (gain normalised):\")\n",
        "print((fi / fi.sum() * 100).round(2).head(20))   # show top-20 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozH7uHbZzzUO"
      },
      "source": [
        "INCLUDES THE ERROR AND RATIO OF DISTANCES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVLHFOL9xw_P",
        "outputId": "3fc3f122-b3fb-49ae-92c6-a5fc4bb13d06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007259 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2154\n",
            "[LightGBM] [Info] Number of data points in the train set: 117998, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 910.000000\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n",
            "INCLUDES THE ERROR AND RATIO OF DISTANCES 190.6 s   RMSE 357.1 s\n",
            "\n",
            "ðŸ”Ž  Top features (gain normalised):\n",
            "begin_lng     11.78\n",
            "begin_lat     11.62\n",
            "end_lng       11.55\n",
            "end_lat       11.45\n",
            "doy           10.62\n",
            "hour           8.31\n",
            "osrm_sec       7.75\n",
            "ratio_len      7.72\n",
            "month_idx      7.53\n",
            "err_len_km     7.41\n",
            "dow            4.26\n",
            "Name: gain, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "BASE = [\n",
        "    \"begin_lat\",\"begin_lng\",\"end_lat\",\"end_lng\",\n",
        "    \"osrm_sec\",\n",
        "    \"hour\",\"dow\", \"month_idx\",\"doy\"\n",
        "]\n",
        "\n",
        "df[\"ratio_len\"]   = df[\"km_pred\"] / df[\"osrm_km\"]\n",
        "df[\"err_len_km\"]  = (df[\"km_pred\"] - df[\"osrm_km\"]).abs()\n",
        "\n",
        "FEATURES_DUR = BASE + [\"ratio_len\", \"err_len_km\"]\n",
        "TARGET_DUR   = \"duration_sec\"\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "        df[FEATURES_DUR], df[TARGET_DUR], test_size=0.2, random_state=SEED)\n",
        "\n",
        "duration_model = lgb.LGBMRegressor(\n",
        "        objective=\"regression_l1\",\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.05,\n",
        "        num_leaves=127,\n",
        "        subsample=0.8,\n",
        "        min_data_in_leaf=30,\n",
        "        random_state=SEED,\n",
        ").fit(X_tr, y_tr)\n",
        "\n",
        "\n",
        "mae = mean_absolute_error(y_te, duration_model.predict(X_te))\n",
        "rmse = root_mean_squared_error(y_te, duration_model.predict(X_te))\n",
        "\n",
        "print(f\"INCLUDES THE ERROR AND RATIO OF DISTANCES {mae:.1f} s   RMSE {rmse:.1f} s\")\n",
        "results.append((\"Ratio of OSRM and Predicted and Error Bias\", mae, rmse))\n",
        "\n",
        "fi = (pd.Series(duration_model.feature_importances_,\n",
        "                index=X_tr.columns,\n",
        "                name=\"gain\")\n",
        "        .sort_values(ascending=False))\n",
        "\n",
        "print(\"\\nðŸ”Ž  Top features (gain normalised):\")\n",
        "print((fi / fi.sum() * 100).round(2).head(20))   # show top-20 %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "5ZNKlKUwK9B_",
        "outputId": "dd3ff2d9-503e-4c10-c12a-50b9420ab7c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: C:\\Users\\aless\\OneDrive - Nexus365\\Thesis\\driver_data\\models\\duration\\duration_results\\v4\\leader_42_original_0075_v2.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "pd.set_option(\"display.max_colwidth\", None)  # show full text in any column\n",
        "\n",
        "leader = (\n",
        "    pd.DataFrame(results, columns=[\"Model\",\"MAE\",\"RMSE\"])\n",
        "      .sort_values(\"MAE\")\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "leader\n",
        "PROJECT_ROOT = Path.cwd().resolve().parents[0]   \n",
        "out = PROJECT_ROOT / \"duration\" / \"duration_results\" / \"v4\" / f\"leader_{SEED}_{EXTENSION}.csv\"\n",
        "os.makedirs(out.parent, exist_ok=True) \n",
        "leader.to_csv(out, index=False)\n",
        "print(\"Wrote:\", out)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "driver_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
